{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KX49HVN7KxXz"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk.corpus import stopwords, twitter_samples\n",
        "\n",
        "from utils import (cosine_similarity, get_dict,\n",
        "                   process_tweet)\n",
        "from os import getcwd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_embeddings_subset = pickle.load(open('en_embeddings.p','rb'))\n",
        "fr_embeddings_subset = pickle.load(open('fr_embeddings.p','rb'))"
      ],
      "metadata": {
        "id": "7LBA02gZYfJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding size\n",
        "len(en_embeddings_subset) , len(fr_embeddings_subset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ep1hfI-VaFBO",
        "outputId": "f0e36b0a-5d7e-41be-d078-6a8226e718a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6370, 5766)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding dim\n",
        "en_embeddings_subset['the'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P55xA6C_N6P",
        "outputId": "dc1a5884-db25-4d41-8097-8a3842454002"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# english to french translation\n",
        "en_fr_train = get_dict('en-fr.train.txt')\n",
        "en_fr_test = get_dict('en-fr.test.txt')"
      ],
      "metadata": {
        "id": "GwocJwxCae0V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a0f092-55a7-4318-a917-e25c45e83f3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/utils.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  en = my_file.loc[i][0]\n",
            "/content/utils.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  fr = my_file.loc[i][1]\n",
            "/content/utils.py:55: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  en = my_file.loc[i][0]\n",
            "/content/utils.py:56: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
            "  fr = my_file.loc[i][1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(en_fr_train), len(en_fr_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aovx1X_beO2",
        "outputId": "b30c0091-f5e4-4549-97d1-e4d576ead535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 1500)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# first 5 words in english to french data\n",
        "{ i : en_fr_train[i] for i in list(en_fr_train.keys())[:5] }"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScUAEx_Z_18w",
        "outputId": "fadd46e3-2ad2-4a80-e95b-d78af83056a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'the': 'la', 'and': 'et', 'was': 'Ã©tait', 'for': 'pour', 'that': 'cela'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_matrices(en_fr_data, en_embed, fr_embed):\n",
        "\n",
        "  X, Y = [],[]\n",
        "\n",
        "  for i, (en_word,fr_word) in enumerate(en_fr_data.items()):\n",
        "\n",
        "    # ensure that words in embedding\n",
        "    if en_word in  en_embed.keys() and fr_word in fr_embed.keys():\n",
        "      X.append(en_embed[en_word])\n",
        "      Y.append(fr_embed[fr_word])\n",
        "\n",
        "  return np.vstack(X),np.vstack(Y)"
      ],
      "metadata": {
        "id": "NFgrUBXLbh5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X,Y = get_matrices(en_fr_train, en_embeddings_subset, fr_embeddings_subset)"
      ],
      "metadata": {
        "id": "TRbBZfIEd94B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape , Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EX63wfFt0xST",
        "outputId": "ca314db6-bd76-4e99-bbc7-b6e931e2d682"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4932, 300), (4932, 300))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_loss(X, Y, R):\n",
        "\n",
        "  m = X.shape[0]\n",
        "\n",
        "  # difference between XR and Y\n",
        "  diff = np.dot(X,R) - Y\n",
        "\n",
        "  # ferbenius norm\n",
        "  diff_squared = diff ** 2\n",
        "  sum_diff_squared = np.sum(diff_squared)\n",
        "  loss = sum_diff_squared / m\n",
        "\n",
        "  return loss"
      ],
      "metadata": {
        "id": "4GB61ef55qrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_gradient(X, Y, R):\n",
        "\n",
        "  m = X.shape[0]\n",
        "  gradient = (2 / m) * np.dot(X.T, np.dot(X,R) - Y)\n",
        "\n",
        "  return gradient"
      ],
      "metadata": {
        "id": "1RuvZjxK-qPw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def align_embeddings(X, Y, train_steps=100, learning_rate=0.01):\n",
        "\n",
        "  # training process for R matrics\n",
        "  np.random.seed(129)\n",
        "  R = np.random.rand(X.shape[1],X.shape[1])\n",
        "\n",
        "  for epoch in range(train_steps):\n",
        "\n",
        "    # every 100 step printloss\n",
        "    if epoch % 100 == 0:\n",
        "      loss = compute_loss(X, Y, R)\n",
        "      print(f\"loss at iteration {epoch} is: {loss:.4f}\")\n",
        "\n",
        "    grad = compute_gradient(X,Y,R)\n",
        "\n",
        "    # update R\n",
        "    R -= learning_rate * grad\n",
        "\n",
        "  return R"
      ],
      "metadata": {
        "id": "0Z2urO8qDM4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(129)\n",
        "m = 10\n",
        "n = 5\n",
        "X_ = np.random.rand(m, n)\n",
        "Y_ = np.random.rand(m, n) * .1\n",
        "R = align_embeddings(X_, Y_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueIDCrsJfkEj",
        "outputId": "6859aae5-871c-4b8b-dd35-ae82d13efd2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at iteration 0 is: 3.7242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "R_train = align_embeddings(X,Y,400,1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpJWDgV8kxjh",
        "outputId": "fc15c2a1-7c1a-4f64-b89d-d3e8924ac05f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss at iteration 0 is: 963.0146\n",
            "loss at iteration 100 is: 2.3146\n",
            "loss at iteration 200 is: 0.6528\n",
            "loss at iteration 300 is: 0.5735\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def nearest_neighbor(v, candidates, k=1):\n",
        "\n",
        "  # v is the selected vector, candidates is all other vectors in data\n",
        "\n",
        "  similarity_l=[]\n",
        "\n",
        "  for vec in candidates:\n",
        "\n",
        "    cos = cosine_similarity(v, vec)\n",
        "    similarity_l.append(cos)\n",
        "  k_idx = np.argsort(similarity_l)\n",
        "\n",
        "  return k_idx[-k:]"
      ],
      "metadata": {
        "id": "aztnGkfvo8SQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v = np.array([1, 0, 1])\n",
        "candidates = np.array([[1, 0, 5], [-2, 5, 3], [2, 0, 1], [6, -9, 5], [9, 9, 9]])\n",
        "nearst_idx = nearest_neighbor(v, candidates, 1)\n",
        "print(\"nearst neighbor index\", nearst_idx)\n",
        "print(\"nearst neighbor vector\", candidates[nearst_idx])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaPI89nnzY0O",
        "outputId": "d6bf21d1-9963-4715-9c64-ddbcb4419ac1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nearst neighbor index [2]\n",
            "nearst neighbor vector [[2 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_vocabulary(X, Y, R):\n",
        "\n",
        "  n_true = 0\n",
        "  pred = np.dot(X,R)\n",
        "\n",
        "  for i in range(len(pred)):\n",
        "\n",
        "    pred_idx = nearest_neighbor(pred[i],Y).item()\n",
        "    # nearest_neighbor returns the vector idx, it should match the true vector idx \"i\"\n",
        "    if pred_idx == i:\n",
        "      n_true += 1\n",
        "\n",
        "  return n_true / len(pred)"
      ],
      "metadata": {
        "id": "p4bPb571zdoy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val, Y_val = get_matrices(en_fr_test, en_embeddings_subset,fr_embeddings_subset)"
      ],
      "metadata": {
        "id": "Bu1xVLR5_jeS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_vocabulary(X_val, Y_val,R_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtV3aoMf_pYh",
        "outputId": "cfc4dbd8-57ac-4fde-f7a6-452379ac78ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5577190542420027"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import twitter_samples,stopwords\n",
        "nltk.download('twitter_samples')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "pos_tweets = twitter_samples.strings('positive_tweets.json')\n",
        "neg_tweets = twitter_samples.strings('negative_tweets.json')\n",
        "\n",
        "all_tweets = pos_tweets + neg_tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEeVcXZEjTii",
        "outputId": "561c2e63-deab-48b8-9829-8885125a8709"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package twitter_samples to /root/nltk_data...\n",
            "[nltk_data]   Package twitter_samples is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_document_embedding(tweet, en_embeddings):\n",
        "\n",
        "  # empty vector for embedding\n",
        "  doc_embed = np.zeros((300))\n",
        "  processed_tweet = process_tweet(tweet)\n",
        "\n",
        "  for word in processed_tweet:\n",
        "\n",
        "    # sum all word embeddings for a specific sentence\n",
        "    doc_embed += en_embeddings.get(word , 0)\n",
        "\n",
        "  return doc_embed"
      ],
      "metadata": {
        "id": "faTyAPSXBYof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tweet = \"RT @Twitter @chapagain Hello There! Have a great day. :) #good #morning http://chapagain.com.np\"\n",
        "\n",
        "tweet_embedding = get_document_embedding(custom_tweet, en_embeddings_subset)\n",
        "tweet_embedding.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9k3-iEp3lGBc",
        "outputId": "21cf1fc5-ec08-40bd-8444-1ef92374b19c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_document_vecs(all_docs, en_embeddings):\n",
        "\n",
        "  embedding_matrix_l = []\n",
        "  ind2embed_dict = {}\n",
        "\n",
        "  for i, doc in enumerate(all_docs):\n",
        "\n",
        "    doc_embed = get_document_embedding(doc,en_embeddings)\n",
        "    embedding_matrix_l.append(doc_embed)\n",
        "    ind2embed_dict[i] = doc_embed\n",
        "\n",
        "  embedding_matrix = np.vstack(embedding_matrix_l)\n",
        "\n",
        "  return embedding_matrix, ind2embed_dict"
      ],
      "metadata": {
        "id": "uSdK4QnMlIPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix, ind2embed_dict = get_document_vecs(all_tweets, en_embeddings_subset)"
      ],
      "metadata": {
        "id": "xgYVLuI-oVGE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXqdIv_boeZF",
        "outputId": "16960ed5-d8fa-4246-ef56-0b9c3fcdbb80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# {k:v for k, v in list(ind2embed_dict.items())[:1]}"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dMUv695eEXrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_VECS = len(all_tweets)\n",
        "N_DIMS = len(ind2embed_dict[1])\n",
        "\n",
        "N_PLANES = 10\n",
        "N_UNIVERSES = 25\n",
        "\n",
        "# each plane has a dim 300 * 10\n",
        "np.random.seed(0)\n",
        "planes_l = [np.random.normal(size=(N_DIMS, N_PLANES))\n",
        "            for _ in range(N_UNIVERSES)]"
      ],
      "metadata": {
        "id": "puHLdMJMrCj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hash_value_of_vector(v, planes):\n",
        "\n",
        "  proj = np.dot(v, planes)\n",
        "  sign = np.sign(proj)>=0\n",
        "  h = np.squeeze(sign)\n",
        "  hash = 0\n",
        "\n",
        "  for i in range(planes.shape[1]):\n",
        "\n",
        "    # hashing equation\n",
        "    hash += np.power(2,i) * h[i]\n",
        "\n",
        "  return int(hash)"
      ],
      "metadata": {
        "id": "qSpMEshYNQEI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(32)\n",
        "idx = 0\n",
        "planes = planes_l[idx]  # get one 'universe' of planes to test the function\n",
        "vec = np.random.rand(1, 300)\n",
        "print(f\"{hash_value_of_vector(vec, planes)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKRmBs3tPk-w",
        "outputId": "1eb6b313-9aee-47dc-9927-eae71f87aaff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def make_hash_table(vecs, planes):\n",
        "\n",
        "  num_buckets = 2 ** planes.shape[1]\n",
        "\n",
        "  hash_table = {i : [] for i in range(num_buckets)}\n",
        "  id_table = {i : [] for i in range(num_buckets)}\n",
        "\n",
        "  for i, vec in enumerate(vecs):\n",
        "\n",
        "    h = hash_value_of_vector(vec, planes)\n",
        "    hash_table[h].append(vec)\n",
        "    id_table[h].append(i)\n",
        "\n",
        "  return hash_table, id_table"
      ],
      "metadata": {
        "id": "wfs2YgiMSKwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "planes = planes_l[0]  # get one 'universe' of planes to test the function\n",
        "vec = np.random.rand(1, 300)\n",
        "print(planes.shape,'')\n",
        "\n",
        "tmp_hash_table, tmp_id_table = make_hash_table(embedding_matrix, planes)\n",
        "\n",
        "print(f\"The hash table at key 0 has {len(tmp_hash_table[0])} document vectors\")\n",
        "print(f\"The id table at key 0 has {len(tmp_id_table[0])}\")\n",
        "print(f\"The first 5 document indices stored at key 0 of are {tmp_id_table[0][0:5]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UNLcKpqeZ2dq",
        "outputId": "47e5ade4-35c6-4f54-b23f-f1d5dfe19b32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(300, 10) \n",
            "The hash table at key 0 has 3 document vectors\n",
            "The id table at key 0 has 3\n",
            "The first 5 document indices stored at key 0 of are [3276, 3281, 3282]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hash_tables = []\n",
        "id_tables = []\n",
        "\n",
        "for i in range(N_UNIVERSES):\n",
        "\n",
        "  plane = planes_l[i]\n",
        "  hash_table, id_table = make_hash_table(embedding_matrix, plane)\n",
        "\n",
        "  hash_tables.append(hash_table)\n",
        "  id_tables.append(id_table)"
      ],
      "metadata": {
        "id": "cYaUvwAZ5D_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def approximate_knn(doc_id, v, planes_l, k=1, num_universes_to_use=N_UNIVERSES):\n",
        "\n",
        "  vecs_to_consider_l = list()\n",
        "  ids_to_consider_l = list()\n",
        "  ids_to_consider_set = set()\n",
        "\n",
        "  for universe in range(num_universes_to_use):\n",
        "\n",
        "    planes = planes_l[universe]\n",
        "\n",
        "    hash_value = hash_value_of_vector(v,planes)\n",
        "\n",
        "    hash_table = hash_tables[universe]\n",
        "    doc_vectors_l = hash_table[hash_value]\n",
        "\n",
        "    id_table = id_tables[universe]\n",
        "    ids_to_consider = id_table[hash_value]\n",
        "\n",
        "    ids_to_consider_l.append(ids_to_consider)\n",
        "\n",
        "    if doc_id in ids_to_consider:\n",
        "      ids_to_consider.remove(doc_id)\n",
        "\n",
        "    for i, id in enumerate(ids_to_consider):\n",
        "\n",
        "      if id not in ids_to_consider_set:\n",
        "\n",
        "        vecs_to_consider_l.append(doc_vectors_l[i])\n",
        "\n",
        "        ids_to_consider_l.append(id)\n",
        "\n",
        "        ids_to_consider_set.add(id)\n",
        "\n",
        "  vecs_to_consider_arr = np.array(vecs_to_consider_l)\n",
        "\n",
        "  nearest_neighbor_idx_l = nearest_neighbor(v, vecs_to_consider_arr, k=k)\n",
        "\n",
        "  nearest_neighbor_ids = [ids_to_consider_l[i] for i in nearest_neighbor_idx_l]\n",
        "\n",
        "  return nearest_neighbor_ids"
      ],
      "metadata": {
        "id": "MdMM_mqL-9oO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_id = 0\n",
        "v = embedding_matrix[doc_id]\n",
        "approximate_knn(doc_id, v, planes_l, 1, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJNuaRogCQN0",
        "outputId": "c32644e6-5011-4dc0-816f-37b06f876822"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1876]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "URB2RyGgJtzp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}